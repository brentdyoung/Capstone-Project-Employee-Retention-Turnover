# -*- coding: utf-8 -*-
"""EDA and Experimental Models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oyW8xXPZTygxjqd-T9mh21l0yCYMVpwG

These models include the use of our selected features and the clustering output, as well as binned features after experimentation. SMOTE has been excluded because it did not help with model accuracy.
Data formatting has been added to this new data set for better coefficient analysis.

Additionally, all previous feature analysis and EDA has been included in this notebook as the final notebook.

# Notebook and Data Setup
"""

# installing package that lets me use CSV files in google drive

# comment the line out below because it only needs to be run once
!pip install -U -q PyDrive

# ==================================
# Packages 
# ==================================

# data manipulation and visualization packages
import pandas as pd
import numpy as np
import random as rn
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline 

# package for oversampling (SMOTE)
from imblearn.over_sampling import SMOTE

# modeling packages
import statsmodels.api as sm
import statsmodels.formula.api as smf
from xgboost import XGBClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC, LinearSVC
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LassoCV
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
from sklearn.model_selection import train_test_split

# model metrics and scoring
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import log_loss
from sklearn.metrics import classification_report

# packages specific to neural network
from keras import backend as K
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop
from keras.utils import to_categorical
import tensorflow as tf

# These are used for getting data from Google Drive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# Authenticate using the four packages above and create the PyDrive client (i.e. login to get data from Google Drive)
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

# Using the two lines below to hide a warning message about visualization
import warnings
warnings.filterwarnings("ignore")

# Make sure pandas prints all columns
pd.set_option('display.max_columns', None)

# ==================================
# Read/Pull in Data
# ==================================

# Copied the link to the IBM Data set below in the variable called 'link'
# AKA test
# original feature selection dataset:
#link_holdout = 'https://drive.google.com/open?id=1mGEmpon2Vt3vE0Q0EsIW73xD5f6HE3qj'
# new data set with clustering:
link_holdout = 'https://drive.google.com/open?id=15Nit1qSPXbIlRGR3ZKp-ZVvFposF04T8'


# AKA training
# original feature selection dataset:
#link_full_data = 'https://drive.google.com/open?id=1b1eBnwxQTnhOGW1a75ZHZ25Ku9UrQTVz'
# new data set with clustering:
link_full_data = 'https://drive.google.com/open?id=1b0ECMaCfK_D6CLk4aUyAVIlQaxc_XNS0'

# We only need the portion of the link after ?id=
fluff, id = link_holdout.split('=')
print (id) # Verify that you have everything after '='
fluff, id2 = link_full_data.split('=')
print (id2)

# The id above looks good, now pull the data into a dataframe using the id
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('WA_Fn-UseC_-HR-Employee-Attrition_test.csv')  
df_holdout = pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition_test.csv')
# Dataset is now stored in a Pandas Dataframe

downloaded = drive.CreateFile({'id':id2})
downloaded.GetContentFile('WA_Fn-UseC_-HR-Employee-Attrition_train.csv')  
df_full_data = pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition_train.csv')
# Dataset is now stored in a Pandas Dataframe

"""#Exploratory Data Analysis"""

#Entire workforce - Plot distribution of all the continuous variables in the data set
df_full_data[df_full_data.dtypes[(df_full_data.dtypes=="float64")|(df_full_data.dtypes=="int64")].index.values].hist(figsize=[16,16]);

#summary statistics of entire workforce - count, mean, etc, min, 25%, 50%, 75% & max
statData = df_full_data.describe(include='all')
statData

#Check for nullvalues
df_full_data.isnull().any() #No null values

#Count number of employees who left
df_full_data['Attrition'].value_counts()  #No=1233; Yes=237

#Calculate attrition_rate
attrition_rate = df_full_data.Attrition.value_counts() / len(df_full_data)
attrition_rate

#Mean comparison of all continuous variables between employees who left vs stayed 
meanData = df_full_data.groupby('Attrition').mean()
#df_full_data.groupby('Attrition').describe().unstack(1)  #Summary statistics comparing left vs stayed
meanData

#can export average_TFIDF_DF to csv and explore further if necessary
#meanData.to_csv('/Users/AgnesCheng/Desktop/498/Project/meandf_full_data.csv', encoding='utf-8', index=True)

df_full_data.Attrition.unique() #'Yes', 'No'

df_full_data.BusinessTravel.unique() #'Travel_Rarely', 'Travel_Frequently', 'Non-Travel'

df_full_data.Department.unique() #'Sales', 'Research & Development', 'Human Resources'

df_full_data.EducationField.unique() #'Life Sciences', 'Other', 'Medical', 'Marketing','Technical Degree', 'Human Resources'

df_full_data.Gender.unique() #'Female', 'Male'

df_full_data.MaritalStatus.unique() #'Single', 'Married', 'Divorced'

df_full_data.Over18.unique() #'Y'

df_full_data.OverTime.unique() #'Yes', 'No'

#Turnover by Department
pd.crosstab(df_full_data.Department,df_full_data.Attrition).plot(kind='bar')
plt.title('Turnover Frequency for Department')
plt.xlabel('Department')
plt.ylabel('Frequency of Turnover')
plt.savefig('department_bar_chart')

#Turnover Proportion by Department
table=pd.crosstab(df_full_data.Department, df_full_data.Attrition)
table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)
plt.title('Stacked Bar Chart of Department vs Turnover')
plt.xlabel('Department')
plt.ylabel('Proportion of Employees')
plt.savefig('department_chart')

#Turnover Proportion by BusinessTravel
table=pd.crosstab(df_full_data.BusinessTravel, df_full_data.Attrition)
table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)
plt.title('Stacked Bar Chart of Business Travel vs Turnover')
plt.xlabel('Business Travel')
plt.ylabel('Proportion of Employees')
plt.savefig('business_travel_chart')

#Turnover Proportion by EducationField
table=pd.crosstab(df_full_data.EducationField, df_full_data.Attrition)
table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)
plt.title('Stacked Bar Chart of Education Field vs Turnover')
plt.xlabel('Education Field')
plt.ylabel('Proportion of Employees')
plt.savefig('education_field_chart')

#Turnover Proportion by Gender
table=pd.crosstab(df_full_data.Gender, df_full_data.Attrition)
table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)
plt.title('Stacked Bar Chart of Gender vs Turnover')
plt.xlabel('Gender')
plt.ylabel('Proportion of Employees')
plt.savefig('gender_chart')

#Turnover Proportion by MaritalStatus
table=pd.crosstab(df_full_data.MaritalStatus, df_full_data.Attrition)
table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)
plt.title('Stacked Bar Chart of Marital Status vs Turnover')
plt.xlabel('Marital Status')
plt.ylabel('Proportion of Employees')
plt.savefig('marital_status_chart')

#Turnover Proportion by OverTime
table=pd.crosstab(df_full_data.OverTime, df_full_data.Attrition)
table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)
plt.title('Stacked Bar Chart of Over Time vs Turnover')
plt.xlabel('Over Time')
plt.ylabel('Proportion of Employees')
plt.savefig('over_time_chart')

###############################################################################
#Check for Outliers
###############################################################################

statdata2 = df_full_data.describe().transpose()

#Outliers are:
#Data point that falls outside of 1.5 times of an interquartile range above the 3rd quartile and below the 1st quartile
#iqr_df = df_full_data.quantile([.25,.75]).transpose()
#iqr = q3 - q1
#lower_bound = q1 -(1.5 * iqr) 
#upper_bound = q3 +(1.5 * iqr) 

statdata2.rename(columns={'25%': 'q1', '50%':'q2', '75%':'q3'}, inplace=True)

statdata2['lower_bound'] = statdata2.apply(lambda row: row.q1 -(1.5 * (row.q3 - row.q1)), axis=1)
statdata2['upper_bound'] = statdata2.apply(lambda row: row.q3 +(1.5 * (row.q3 - row.q1)), axis=1)

statdata2

#MonthlyIncome > 1.5 of the upperbound but it should not be considered an outlier since this is expected.
highInc = df_full_data[df_full_data.MonthlyIncome > 16581]
#There are 114 employees with Monthly income > 1.5*q3
highInc

###############################################################################
#Drop columns with the same values & encode categorical variables
###############################################################################

#Check columns to confirm if it contains the same value in all rows
df_full_data.EmployeeCount.unique() #1

df_full_data.Over18.unique() #Y

df_full_data.StandardHours.unique() #80

#Drop columns containing same values in all rows from dataframe using axis=1 (axis=0 drops rows)
data2 = df_full_data.drop(["EmployeeCount", "Over18", "StandardHours"], axis=1)
data2.info()

#Initialize LabelEncoder() to encode a catagorical variables in data2 dataframe to int64
#Categorical variable to be encoded: Attrition, BusinessTravel, Department, EducationField, Gender, JpbRole, MaritalStatus, OverTime 
leData = data2.apply(LabelEncoder().fit_transform)
leData.info()

#Drop categorical variables from dataset to create the boxplots
df_full_data.info()

contData = leData.drop(["BusinessTravel", "Department", "EducationField", "Gender", "JobRole", "MaritalStatus", "OverTime", "PerformanceRating"], axis=1)
contData.head()

###############################################################################
# Boxplots of Continuous Variable by Attrition 0=No, 1=Yes
###############################################################################

l = contData.columns.values
numColumns=25
numRows = len(l)-1/numColumns
plt.figure(figsize=(numColumns*2,5*numRows))

for i in range(0,len(l)):
    plt.subplot(numRows + 1,numColumns,i+1)
    sns.set_style('whitegrid')
    sns.boxplot(x=contData.Attrition, y=contData[l[i]], color='royalblue',orient='v', notch=True)
    plt.tight_layout()
plt.savefig('BoxPlots_ContinuousVarByAttrition')

###############################################################################
#Correlation Analysis
###############################################################################

contData2 = contData.drop(["EmployeeNumber", "Attrition"], axis=1)


plt.figure(figsize= (10,10), dpi=100)
sns.heatmap(contData2.corr(),cmap='Blues_r') #cmap to  change color
#https://datascience.stackexchange.com/questions/10459/calculation-and-visualization-of-correlation-matrix-with-pandas
plt.savefig('corr_heatmap')

#Plot a correlation map for all numeric variables
f,ax = plt.subplots(figsize=(20, 20))
sns.heatmap(contData2.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax, cmap='Blues_r')

#https://nbviewer.jupyter.org/github/PBPatil/Exploratory_Data_Analysis-Wine_Quality_Dataset/blob/master/winequality_white.ipynb
#https://towardsdatascience.com/exploratory-data-analysis-8fc1cb20fd15
#https://towardsdatascience.com/feature-selection-with-pandas-e3690ad8504b
#attrition correlation matrix
contData3 = contData.drop(["EmployeeNumber"], axis=1)

k = 32 #number of variables for heatmap
cols = contData3.corr().nlargest(k, 'Attrition')['Attrition'].index
cm = contData3[cols].corr()
plt.figure(figsize=(50,30))
#sns.heatmap(cm, annot=True, cmap = 'Blues_r')
sns.heatmap(cm, annot=True)
plt.savefig('corr_heatmap_attrition')

#>>>>>>BusinessTravel has little correlation to Attrition .: 
#Since correlation is zero we can infer there is no linear relationship between these two predictors.However it is safe to drop these features in case you're applying Linear Regression model to the dataset.

#Correlation with output variable
cor = contData3.corr()
cor_target = abs(cor["Attrition"])
#Selecting highly correlated features
relevant_features = cor_target[cor_target>0.1]
relevant_features

#Correlation with YearsAtCompany variable
cor = contData3.corr()
cor_target = abs(cor["YearsAtCompany"])
#Selecting highly correlated features
relevant_features = cor_target[cor_target>0.5]
relevant_features

#Correlation with Age variable
cor = contData3.corr()
cor_target = abs(cor["Age"])
#Selecting highly correlated features
relevant_features = cor_target[cor_target>0.5]
relevant_features

#Correlation with MonthlyIncome variable
cor = contData3.corr()
cor_target = abs(cor["MonthlyIncome"])
#Selecting highly correlated features
relevant_features = cor_target[cor_target>0.5]
relevant_features

#Correlation with TotalWorkingYears variable
cor = contData3.corr()
cor_target = abs(cor["TotalWorkingYears"])
#Selecting highly correlated features
relevant_features = cor_target[cor_target>0.5]
relevant_features

"""#Feature Selection"""

df_full_data.columns

###############################################################################
#Feature Selection
###############################################################################
#Drop variables w/ high collinearity
drop_columns1 = ["EmployeeNumber", "BusinessTravel", "PercentSalaryHike", "YearsWithCurrManager", "YearsInCurrentRole", "JobLevel", "MonthlyIncome"]
df_full_data2 = df_full_data.drop(drop_columns1, axis=1)
#df_full_data = df_full_data.drop(["EmployeeNumber", "BusinessTravel", "PercentSalaryHike", "YearsWithCurrManager", "YearsInCurrentRole", "JobLevel", "MonthlyIncome"], axis=1)

#Drop columns containing same values in all rows from dataframe using axis=1 (axis=0 drops rows)
drop_columns2 = ["EmployeeCount", "Over18", "StandardHours"]
#df_full_data = df_full_data.drop(["EmployeeCount", "Over18", "StandardHours"], axis=1)
df_full_data2 = df_full_data2.drop(drop_columns2, axis=1)

df_full_data2.columns

#Initialize LabelEncoder() to encode a catagorical variables in df_full_data to int64
#Categorical variable to be encoded: Attrition, BusinessTravel, Department, EducationField, Gender, JpbRole, MaritalStatus, OverTime 
leData2 = df_full_data.apply(LabelEncoder().fit_transform)
leData2.info() 

response_var = 'Attrition'
X = leData2.drop('Attrition', axis=1)
y = leData2[response_var]

#Split df into train and test
#X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.15, random_state=123, stratify=y)

#1) Feature Selection using DecisionTreeClassier()
#Source: https://www.kaggle.com/hjlee0421/predicting-employee-kernelover

dtree = tree.DecisionTreeClassifier(
    #max_depth=3,
    class_weight="balanced",
    min_weight_fraction_leaf=0.01
    )
dtree = dtree.fit(X,y)

## plot the importances ##
importances = dtree.feature_importances_
feat_names = leData2.drop(['Attrition'],axis=1).columns

indices = np.argsort(importances)[::-1]
plt.figure(figsize=(12,6))
plt.title("Feature importances by DecisionTreeClassifier")
plt.bar(range(len(indices)), importances[indices], color='lightblue',  align="center")
plt.step(range(len(indices)), np.cumsum(importances[indices]), where='mid', label='Cumulative')
plt.xticks(range(len(indices)), feat_names[indices], rotation='vertical',fontsize=14)
plt.xlim([-1, len(indices)])
plt.show()
plt.savefig('DecisionTreeFeaturesImportance')

#2) Feature Selection using Recursive Feature Elimination (RFE) 
model = LogisticRegression()

rfe = RFE(model, 15) #Number of Features Selected
rfe = rfe.fit(X,y)

print("Num Features: %s" % (rfe.n_features_))
print("Selected Features: %s" % (rfe.support_))
print("Feature Ranking: %s" % (rfe.ranking_))

sf = rfe.support_
fr = rfe.ranking_
featureNames = list(X.columns.values) 

#Create empty dataframe
RFE_df = pd.DataFrame()
#Add sf, fr and featureNames to the dataframe
RFE_df = pd.DataFrame(sf, fr)
RFE_df['featureNames'] = featureNames

#3)Feature Selection using Backward Elimination
#Adding constant column of ones, mandatory for sm.OLS model

X_1 = sm.add_constant(X)
#Fitting sm.OLS model
model = sm.OLS(y,X_1).fit()
model.pvalues

#Backward Elimination
cols = list(X.columns)
pmax = 1
while (len(cols)>0):
    p= []
    X_1 = X[cols]
    X_1 = sm.add_constant(X_1)
    model = sm.OLS(y,X_1).fit()
    p = pd.Series(model.pvalues.values[1:],index = cols)      
    pmax = max(p)
    feature_with_p_max = p.idxmax()
    if(pmax>0.05):
        cols.remove(feature_with_p_max)
    else:
        break
selected_features_BE = cols
print(selected_features_BE)

#4) Feature Selection using Embedded method
#Source: https://towardsdatascience.com/feature-selection-with-pandas-e3690ad8504b
reg = LassoCV()
reg.fit(X, y)
print("Best alpha using built-in LassoCV: %f" % reg.alpha_)
print("Best score using built-in LassoCV: %f" %reg.score(X,y))
coef = pd.Series(reg.coef_, index = X.columns)
print(coef)

print("Lasso picked " + str(sum(coef != 0)) + " variables and eliminated the other " +  str(sum(coef == 0)) + " variables")

imp_coef = coef.sort_values()
import matplotlib
matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)
imp_coef.plot(kind = "barh")
plt.title("Feature importance using Lasso Model")

#Source: https://towardsdatascience.com/feature-selection-techniques-in-machine-learning-with-python-f24e7da3f36e
#5) Univariate Feature Selection
#apply SelectKBest class to extract top 10 best features
bestfeatures = SelectKBest(score_func=chi2, k=10)
fit = bestfeatures.fit(X,y)
dfscores = pd.DataFrame(fit.scores_)
dfcolumns = pd.DataFrame(X.columns)
#concat two dataframes for better visualization 
featureScores = pd.concat([dfcolumns,dfscores],axis=1)
featureScores.columns = ['Specs','Score']  #naming the dataframe columns
print(featureScores.nlargest(10,'Score'))  #print 10 best features

"""# Prep Data for Modeling"""

# Drop columns irrelevant to our analysis
#drop_columns = ['BusinessTravel','Department','Education','EducationField','EmployeeCount','Gender','HourlyRate','JobLevel','JobRole','MonthlyIncome','MonthlyRate','Over18','PercentSalaryHike','StandardHours','StockOptionLevel','YearsInCurrentRole','YearsSinceLastPromotion','YearsWithCurrManager']
# keep HourlyRate, MonthlyRate for bins
drop_columns = ['BusinessTravel','Department','Education','EducationField','EmployeeCount','Gender','JobLevel','JobRole','MonthlyIncome','Over18','PercentSalaryHike','StandardHours','StockOptionLevel','YearsInCurrentRole','YearsSinceLastPromotion','YearsWithCurrManager']
df_holdout = df_holdout.drop(drop_columns, axis=1)
df_full_data = df_full_data.drop(drop_columns, axis=1)

df_holdout.set_index('EmployeeNumber',inplace=True)
df_full_data.set_index('EmployeeNumber',inplace=True)

"""Create new variables with bins"""

###############################################################################
#Data Binning
###############################################################################


# Age Custom binning #stacked bar on attrition
# Gen Z 18-24, Gen Y 25-33, Xennial 34-39, Gen X 40-54, Baby Boomers 55-75,  
#custombins = [18, 25, 40, 55, 75, 100]
#df_full_data['AgeRange'] = pd.cut(df_full_data['Age'], custombins, labels=['18_24', '25_39', '40_54', '55_75', 'Over75'])
#df_full_data['AgeRange'].value_counts(sort = False)
#df_holdout['AgeRange'] = pd.cut(df_holdout['Age'], custombins, labels=['18_24', '25_39', '40_54', '55_75', 'Over75'])
#df_holdout['AgeRange'].value_counts(sort = False)

# New bin tests
# retirement = ~67yrs old
# job hoppers usually 18-35
#custombins = [18, 36, 46, 56, 66, 100]
#df_full_data['AgeRange'] = pd.cut(df_full_data['Age'], custombins, labels=['18_35', '36_45', '46_55', '56_65', 'Over60'])
#df_full_data['AgeRange'].value_counts(sort = False)
#df_holdout['AgeRange'] = pd.cut(df_holdout['Age'], custombins, labels=['18_30', '31_40', '41_50', '51_60', 'Over60'])
#df_holdout['AgeRange'].value_counts(sort = False)


#DailyRate Binning 100-1500
# Equal width binning - 5 bins
#custombins = [100, 380, 660, 940, 1220, 1500]
#df_full_data['DailyRateRange'] = pd.cut(df_full_data['DailyRate'], custombins, labels=['100_379', '380_659', '660_939', '940_1219', '1220_1500'])
#df_full_data['DailyRateRange'].value_counts(sort = False)
#df_holdout['DailyRateRange'] = pd.cut(df_holdout['DailyRate'], custombins, labels=['100_379', '380_659', '660_939', '940_1219', '1220_1500'])
#df_holdout['DailyRateRange'].value_counts(sort = False)

#Distance Binning
custombins = [1, 5, 10, 20, 30, 1000]
df_full_data['DistanceFromHomeRange'] = pd.cut(df_full_data['DistanceFromHome'], custombins, labels=['1_4', '5_9', '10_19', '20_30', 'Over30'])
df_full_data['DistanceFromHomeRange'].value_counts(sort = False)
df_holdout['DistanceFromHomeRange'] = pd.cut(df_holdout['DistanceFromHome'], custombins, labels=['1_4', '5_9', '10_19', '20_30', 'Over30'])
df_holdout['DistanceFromHomeRange'].value_counts(sort = False)

#HourlyRate - Equal width binning - 5 bins
#custombins = [29, 44, 58, 72, 86, 100]
#df_full_data['HourlyRateRange'] = pd.cut(df_full_data['HourlyRate'], custombins, labels=['29_43', '44_57', '58_71', '72_85', '86_100'])
#df_full_data['HourlyRateRange'].value_counts(sort = False)
#df_holdout['HourlyRateRange'] = pd.cut(df_holdout['HourlyRate'], custombins, labels=['29_43', '44_57', '58_71', '72_85', '86_100'])
#df_holdout['HourlyRateRange'].value_counts(sort = False)

#MonthlyRate - Equal width binning - 5 bins
#custombins = [2000, 7000, 12000, 17000, 22000, 28000]
#df_full_data['MonthlyRateRange'] = pd.cut(df_full_data['MonthlyRate'], custombins, labels=['2000_6999', '7000_11999', '12000_16999', '17000_21999', '22000_28000'])
#df_full_data['MonthlyRateRange'].value_counts(sort = False)
#df_holdout['MonthlyRateRange'] = pd.cut(df_holdout['MonthlyRate'], custombins, labels=['2000_6999', '7000_11999', '12000_16999', '17000_21999', '22000_28000'])
#df_holdout['MonthlyRateRange'].value_counts(sort = False)

#TotalWorkingYears Binning - Equal width binning - 3 bins
#custombins = [0, 5, 10, 100]
#custombins = [0, 3, 6, 10, 100]
#df_full_data['TotalWorkingYearsRange'] = pd.cut(df_full_data['TotalWorkingYears'], custombins, labels=['NewGrads', 'EarlyCareer', 'Experienced', 'Senior'])
#df_full_data['TotalWorkingYearsRange'].value_counts(sort = False)
#df_holdout['TotalWorkingYearsRange'] = pd.cut(df_holdout['TotalWorkingYears'], custombins, labels=['NewGrads', 'EarlyCareer', 'Experienced', 'Senior'])
#df_holdout['TotalWorkingYearsRange'].value_counts(sort = False)


#NumCompaniesWorked Binning - Equal width binning - 4 bins
custombins = [0, 3, 6, 10, 100]
df_full_data['NumCompaniesWorkedRange'] = pd.cut(df_full_data['NumCompaniesWorked'], custombins, labels=['0_2', '3_5', '6_10', '10over'])
df_full_data['NumCompaniesWorkedRange'].value_counts(sort = False)
df_holdout['NumCompaniesWorkedRange'] = pd.cut(df_holdout['NumCompaniesWorked'], custombins, labels=['0_2', '3_5', '6_10', '10over'])
df_holdout['NumCompaniesWorkedRange'].value_counts(sort = False)


#YearsAtCompany Binning - Equal width binning - 4 bins
#custombins = [0, 5, 10, 20, 100]
#df_full_data['YearsAtCompanyRange'] = pd.cut(df_full_data['YearsAtCompany'], custombins, labels=['0_4', '5_9', '10_19', '20over'])
#df_full_data['YearsAtCompanyRange'].value_counts(sort = False)
#df_holdout['YearsAtCompanyRange'] = pd.cut(df_holdout['YearsAtCompany'], custombins, labels=['0_4', '5_9', '10_19', '20over'])
#df_holdout['YearsAtCompanyRange'].value_counts(sort = False)


#YearsAtCompany Binning - Equal width binning - 3 bins
custombins = [0, 3, 6, 10, 100]
df_full_data['YearsAtCompanyRange'] = pd.cut(df_full_data['YearsAtCompany'], custombins, labels=['0_2', '3_5', '6_10', '10over'])
df_full_data['YearsAtCompanyRange'].value_counts(sort = False)
df_holdout['YearsAtCompanyRange'] = pd.cut(df_holdout['YearsAtCompany'], custombins, labels=['0_2', '3_5', '6_10', '10over'])
df_holdout['YearsAtCompanyRange'].value_counts(sort = False)

# Below I edit the code from the old data set to match the new variables:
# Convert Attrition to binary format for models
df_holdout['Attrition']=df_holdout['Attrition'].apply(lambda x : 1 if x=='Yes' else 0)
df_full_data['Attrition']=df_full_data['Attrition'].apply(lambda x : 1 if x=='Yes' else 0)

# Convert OverTime to binary format for models
df_holdout['OverTime']=df_holdout['OverTime'].apply(lambda x : 1 if x=='Yes' else 0)
df_full_data['OverTime']=df_full_data['OverTime'].apply(lambda x : 1 if x=='Yes' else 0)

# Convert all other categorical fields into numerical fields
# AKA the test set
df_holdout=pd.get_dummies(df_holdout)
# AKA the training set
df_full_data=pd.get_dummies(df_full_data)
#df_full=pd.get_dummies(df_full)

#temporarily remove columns for binning
# 
drop_columns = ['DistanceFromHome', 'NumCompaniesWorked', 'YearsAtCompany', 'ClusterSegment']
df_holdout = df_holdout.drop(drop_columns, axis=1)
df_full_data = df_full_data.drop(drop_columns, axis=1)

# Drop subdummies to avoid collinearity problem
drop_sub_dummies = ['DistanceFromHomeRange_Over30', 'NumCompaniesWorkedRange_10over', 'YearsAtCompanyRange_10over']
df_holdout = df_holdout.drop(drop_sub_dummies, axis=1)
df_full_data = df_full_data.drop(drop_sub_dummies, axis=1)

# confirm formatting is correct
df_holdout.head(1)

# confirm formatting is correct
df_full_data.head(3)

"""# Split and Normalize Data"""

# Separating the features(x) from the attrition values (y) for shared test/train set
#X_test = df_test.drop(['Attrition'], axis=1)
#y_test = df_test['Attrition'].as_matrix()
#X_train = df_train.drop(['Attrition'], axis=1)
#y_train = df_train['Attrition'].as_matrix()


# Separating the features(x) from the attrition values (y) for full data set (AKA train set)
X = df_full_data.drop(['Attrition'], axis=1)
y = df_full_data['Attrition'].as_matrix()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=24)

# Check amount of samples before SMOTE
print("Length of X training data is :",len(X_train))
print("Length of y training data is :",len(y_train))

#############################
#Comment out Smote because it did not benefit model
#############################

# Apply SMOTE
#smt = SMOTE(random_state=0)
#X_train, y_train = smt.fit_sample(X_train, y_train)
    
# Print SMOTE oversampling data
#smt_data_X = pd.DataFrame(data=X_train)
#smt_data_y= pd.DataFrame(data=y_train,columns=['y'])

# We can Check the numbers of our data
#print("Length of oversampled data is ",len(smt_data_X))
#print("Number of no subscription in oversampled data",len(smt_data_y[smt_data_y['y']==0]))
#print("Number of subscription",len(smt_data_y[smt_data_y['y']==1]))
#print("Proportion of no subscription data in oversampled data is ",len(smt_data_y[smt_data_y['y']==0])/len(smt_data_X))
#print("Proportion of subscription data in oversampled data is ",len(smt_data_y[smt_data_y['y']==1])/len(smt_data_X))

# Check amount of samples after SMOTE
#print("Length of X training data is :",len(X_train))
#print("Length of y training data is :",len(y_train))

# Normalize the training data
sc = StandardScaler()
# Fit the scaler to the training data
X_train = sc.fit_transform(X_train)
# Then standardise both training and test sets with that scaler
X_test = sc.transform (X_test)

"""# Create Definitions for Model Training"""

# Function to Train and Test Machine Learning Model
def train_test_ml_model(X_train, y_train, X_test, Model):
    model.fit(X_train, y_train) # Train the Model
    y_pred = model.predict(X_test) # Use the Model for prediction

    # Test the Model
    cm = confusion_matrix(y_test, y_pred)
    #predictions = [round(value) for value in y_pred]
    accuracy = accuracy_score(y_test, y_pred)

    # Plot/Display the results
    # First, the confusion matrix
    cm_plot(cm, Model)
    print('Accuracy of the Model', Model, str(accuracy) + '%')
    # Add a space for readability
    print(' ')
    # Second, the roc curve plot
    roc_plot(X_test, y_test, model)
    # Third, Log Loss result
    print(' ')
    print('Log Loss: ', log_loss(y_test, y_pred))
        # Add a space for readability
    print(' ')
    print(' ')
    print(classification_report(y_test, y_pred))

# Function to plot confusion matrix
def cm_plot(cm, Model):
    plt.clf()
    plt.figure(figsize=(5,5))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)
    classNames = ['Negative', 'Positive']
    plt.title('Comparison of Prediction Result for ' + Model)
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    tick_marks = np.arange(len(classNames))
    plt.xticks(tick_marks, classNames, rotation=45)
    plt.yticks(tick_marks, classNames)
    s = [['TN','FP'], ['FN', 'TP']]
    for i in range(2):
        for j in range(2):
            plt.text(j,i, str(s[i][j])+" = "+str(cm[i][j]))
    plt.show()

#Function to plot ROC Curve

def roc_plot(X_test, y_test, model):
# calculate the fpr and tpr for all thresholds of the classification
  probs = model.predict_proba(X_test)
  preds = probs[:,1]
  fpr, tpr, threshold = roc_curve(y_test, preds)
  roc_auc = auc(fpr, tpr)

  plt.figure(figsize=(5,5))
  plt.title('Receiver Operating Characteristic')
  plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
  plt.legend(loc = 'lower right')
  plt.plot([0, 1], [0, 1],'r--')
  plt.xlim([0, 1])
  plt.ylim([0, 1])
  plt.ylabel('True Positive Rate')
  plt.xlabel('False Positive Rate')
  plt.show()

# Function to display Cross-Validation Score

def cross_val(X, y, Model):
  # Adding space for readability between functions
  print(' ')
  print(' ')
  from sklearn.model_selection import cross_val_score
  #train model with cv of 10
  cv_scores = cross_val_score(model, X, y, cv=10)
  
  #Display the results
  print('List of Cross-Validation Scores:', cv_scores)
  print('Mean of Cross-Validation Scores:{}'.format(np.mean(cv_scores)))

"""# Model 1: XGBoost Classification
(Parallel Tree Gradient Boosting)
"""

Model = "XGBClassifier()" # Adds to title in viz
model = XGBClassifier() # Create the Model

train_test_ml_model(X_train, y_train, X_test, Model)
cross_val(X, y, Model)

"""# Model 2: K-Nearest Neighbors Classification (KNN)"""

# Attempt 1: Out of Box

#n_neighbors=5 out of the box
Model = "KNeighborsClassifier"
model = KNeighborsClassifier()

train_test_ml_model(X_train,y_train,X_test,Model)
cross_val(X, y, Model)

# Attempt 2: Configuration

Model = "KNeighborsClassifier"
model = KNeighborsClassifier(n_neighbors=8)

train_test_ml_model(X_train,y_train,X_test,Model)
cross_val(X, y, Model)

"""# Model 3: Random Forest Classification"""

# Attempt 1: Out of Box

# this uses default RF values
# Out of the box, RF will use Bootstrapping to resample data
Model = "RandomForestClassifier"
model = RandomForestClassifier()

train_test_ml_model(X_train,y_train,X_test,Model)
cross_val(X, y, Model)

# Attempt 2: Configuration
# n_estimators = number of trees in the forest
# max_features = the maximum number of features Random Forest is allowed to try in individual tree
# min_samples_leaf = leaf is the end node of a decision tree, a smaller leaf makes the model more prone to capturing noise in train data 


#commenting this model out because it takes awhile to run
Model = "RandomForestClassifier"
model = RandomForestClassifier(n_estimators=5000, random_state=0, max_features=.1, max_depth=15)

train_test_ml_model(X_train,y_train,X_test,Model)
cross_val(X, y, Model)

"""# Method 4: SVM"""

Model = "SVC"
model = SVC(probability=True) 
# Note, if we move forward with this model, we cannot use 'True'
# to product the ROC curve because the formatting remove the probability % and 
# results only in answers of 1 or 0.

train_test_ml_model(X_train,y_train,X_test,Model)
cross_val(X, y, Model)

"""# Method 4: LDA"""

Model = "LDA"
model = LinearDiscriminantAnalysis() 

train_test_ml_model(X_train,y_train,X_test,Model)
cross_val(X, y, Model)

"""# Method 5: Logisitic Regression"""

Model = "LogisticRegression"
model = LogisticRegression() 

train_test_ml_model(X_train,y_train,X_test,Model)
cross_val(X, y, Model)

# Transform holdout set to feed into model to get output
X_holdout = df_holdout.drop(['Attrition'], axis=1)
y_holdout = df_holdout['Attrition'].as_matrix()
# Apply transformation from earlier
X_holdout = sc.transform(X_holdout)

# Run the model on our full data so we can get the predictions in one dataset.
final = model.predict(X_holdout)
calc_prob = model.predict_proba(X_holdout)[:, 1]
Final_Output = df_holdout
Final_Output['Probability_of_Attrition'] = calc_prob
Final_Output['Final_Prediction'] = final
Final_Output.head()

# Save Dataframe to CSV
Final_Output.to_csv("Final_Output.csv")

# Exploration of Log Reg Coefficients
# Reference used:
# https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8

import statsmodels.api as sm
import statsmodels.formula.api as smf
logit_model=smf.Logit(y_train, X_train)
results=logit_model.fit()
print(results.summary2())

# Column names for reference above
df_column_name = pd.DataFrame(list(df_full_data.drop(['Attrition'], axis=1).columns.values))
df_column_name.index = np.arange(1, len(df_column_name) + 1)
df_column_name

# note: the new clustering dataset has slightly different columns
#model= smf.logit(formula="Attrition~ ClusterSegment	+ Age + DailyRate + EnvironmentSatisfaction + JobInvolvement + JobSatisfaction + NumCompaniesWorked + RelationshipSatisfaction + TotalWorkingYears + TrainingTimesLastYear + WorkLifeBalance + OverTime + PerformanceRating + MaritalStatus_Divorced + MaritalStatus_Married + MaritalStatus_Single + DistanceFromHomeRange_1_4 + DistanceFromHomeRange_5_9 + DistanceFromHomeRange_10_19 + DistanceFromHomeRange_20_30 + DistanceFromHomeRange_Over30 + NumCompaniesWorkedRange_0_2 + NumCompaniesWorkedRange_3_5 + NumCompaniesWorkedRange_6_10 + NumCompaniesWorkedRange_10over + YearsAtCompanyRange_0_2 + YearsAtCompanyRange_3_5 + YearsAtCompanyRange_6_10 + YearsAtCompanyRange_10over", data= df_full_data).fit(method='lbfgs')
model= smf.logit(formula="Attrition~ Age + DailyRate + EnvironmentSatisfaction + JobInvolvement + JobSatisfaction + RelationshipSatisfaction + TotalWorkingYears + TrainingTimesLastYear + WorkLifeBalance + OverTime + PerformanceRating + MaritalStatus_Divorced + MaritalStatus_Married + MaritalStatus_Single", data= df_full_data).fit()
model.summary()

# GETTING THE ODDS RATIOS, Z-VALUE, AND 95% CI
model_odds = pd.DataFrame(np.exp(model.params), columns= ['OR'])
model_odds['z-value']= model.pvalues
model_odds[['2.5%', '97.5%']] = np.exp(model.conf_int())
model_odds

"""# Model 6: Neural Network"""

# Random seeds
np.random.seed(123)
rn.seed(123)
tf.set_random_seed(123)

# Convert Attrition to one-hot encoding for NN to be able to read
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# Neural Network Architecture

# Create initial set of linear layers
model=Sequential()
# Now, add to our linear layers and note their neurons in each added layer
# Input dimension only needs to be noted for the first layer and it is the number of features/columns
model.add(Dense(input_dim=27, units=8, activation='relu', name='output_1'))
model.add(Dense(units=16, activation='relu', name='output_2'))
# Make sure output later has two neurons for each type of classification of attrition
model.add(Dense(units=2, activation='sigmoid'))

# Compile the Network
# More information on optimizer types:
# https://keras.io/optimizers/
model.compile(optimizer=Adam(lr=0.01), loss='binary_crossentropy', metrics=['accuracy'])
# loss='binary_crossentropy' specifies that your model should optimize the log 
# loss for binary classification.  
# metrics=['accuracy'] specifies that accuracy should be printed out

# Review NN configuration
model.summary()

History = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=1)

model.predict_classes(X_test)

# Log Loss over time
plt.figure(figsize=(5,5))
plt.plot(History.history['loss'])
plt.plot(History.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.legend(['train', 'test'])
plt.show()

# Model accuracy over time
plt.figure(figsize=(5,5))
plt.plot(History.history['acc'])
plt.plot(History.history['val_acc'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['train', 'test'])
plt.show()

print(model.metrics_names)

model.evaluate(X_train,y_train)
# averaged loss and accuracy on train

model.evaluate(X_test,y_test)
# averaged loss and accuracy on text

